{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of Myria as a Federated Database\n",
    "\n",
    "\n",
    "### Setup steps:\n",
    "* Install Raco:\n",
    "    * Follow the steps listed on https://github.com/uwescience/raco/tree/SPJA_federation#setup to set up RACO.\n",
    "* Install SPARK:\n",
    "    * Download the prebuilt HADOOP version from http://spark.apache.org/downloads.html and follow the setup steps on SPARK website to verify if it works. (Make sure you have all the dependencies listed on the page installed)\n",
    "    * Set the SPARK_HOME environment variable to the downloaded SPARK folder and add it to PATH\n",
    "        * On mac, this can be done by adding the following lines to bash_profile or bashrc file:\n",
    "`\n",
    "export SPARK_HOME=</path/to/spark>\n",
    "export PATH=$SPARK_HOME/bin:$PATH\n",
    "`\n",
    "\n",
    "* Install jupyter:\n",
    "    * on mac, this can be done via: `pip install jupyter`\n",
    "    \n",
    "* Run `ipython notebook` command. And browse to this notebook. \n",
    "\n",
    "* Update the path to the input dataset in the code below^: \n",
    "`\n",
    "matA = scan('/path/to/datafile');\n",
    "`\n",
    "\n",
    "^ (As a sample, you can download and use https://github.com/uwescience/raco/blob/SPJA_federation/demo/sample.dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import raco.viz\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.add_packages('com.databricks:spark-csv_2.10:1.4.0')\n",
    "\n",
    "from raco.backends.spark.connection import SparkConnection\n",
    "from raco.backends.spark.catalog import SparkCatalog\n",
    "from raco.backends.spark.algebra import SparkAlgebra\n",
    "\n",
    "from raco.backends.logical import OptLogicalAlgebra\n",
    "from raco.catalog import FromFileCatalog\n",
    "import raco.myrial.interpreter as interpreter\n",
    "import raco.myrial.parser as myrialparser\n",
    "\n",
    "from raco.backends.myria import MyriaLeftDeepTreeAlgebra\n",
    "from raco.backends.myria.connection import MyriaConnection\n",
    "from raco.backends.myria.catalog import MyriaCatalog\n",
    "\n",
    "from raco.backends.federated.connection import FederatedConnection\n",
    "from raco.backends.federated.catalog import FederatedCatalog\n",
    "from raco.backends.federated.algebra import FederatedAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HELPER METHODS TO GET BACKEND CONNECTORS\n",
    "def get_myria_connection():\n",
    "    execution_url = os.environ.get('MYRIAX_REST_HOST', 'localhost')\n",
    "    connection = MyriaConnection(hostname=execution_url, port=8753)\n",
    "    return connection\n",
    "\n",
    "def get_spark_connection():\n",
    "    masterHostname = os.environ.get('sparkurl', 'localhost')\n",
    "    if masterHostname == 'localhost':\n",
    "        return SparkConnection(masterHostname)\n",
    "    return SparkConnection(\"spark://{masterHostname}:7077\".format(masterHostname=masterHostname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Initialize Backend 1\n",
    "myriaconn = get_myria_connection()\n",
    "myriacatalog = MyriaCatalog(myriaconn)\n",
    "\n",
    "##Initialize Backend 2\n",
    "sparkconn = get_spark_connection()\n",
    "sparkcatalog = SparkCatalog.load_from_file(os.path.join(os.path.abspath('./examples/'), 'catalog.py'))\n",
    "\n",
    "##Initialize Federated Backend\n",
    "fed_conn = FederatedConnection([myriaconn, sparkconn])\n",
    "fed_catalog = FederatedCatalog([myriacatalog, sparkcatalog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##The Jaccard Computation expressed as MyriaL query\n",
    "program_fquery=\"\"\"\n",
    "-- Scan netflow data (this resides in Accumulo)\n",
    "NF = scan(netflow);\n",
    "-- Filter the dataset (runs on Accumulo)\n",
    "NFSUB = select SrcAddr as src_ip, DstAddr as dst_ip, 1.0 as value from NF where TotBytes > 100;\n",
    "-- Scan DNS dataset (this is accessible to Spark)\n",
    "DNS = scan('/home/dhutchis/gits/raco/examples/fed_accumulo_spark_c/dnssample_parsed.txt');\n",
    "-- Perform a Join (Automatically move the datasets as necessary)\n",
    "graph = select d1.dns as row, d2.dns as col, n.value\n",
    "\t\tfrom NFSUB n, DNS d1, DNS d2\n",
    "\t    where n.src_ip = d1.ip and n.dst_ip = d2.ip;\n",
    "\n",
    "--Begin Jaccard\n",
    "-- Calculate common neighbours\n",
    "gammas = select a.row as u, b.row as v, count(b.value) as gamma\n",
    "\t\t from graph a, graph b\n",
    "         where a.col == b.col;\n",
    "\n",
    "-- Calculate the out_degree of each vertex\n",
    "out_d = select row, count(value) as od from graph;\n",
    "\n",
    "-- Calculate the Jaccard Coefficients for all pairs (u,v);\n",
    "J = select a.u as src_name, a.v as dst_name, a.gamma/(b.od + c.od - a.gamma) as jaccard_coeff\n",
    "\tfrom gammas a, out_d b, out_d c\n",
    "    where a.u = b.row and a.v = c.row;\n",
    "\n",
    "-- Store the result\n",
    "store(J, nameJaccard);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Parse the query\n",
    "parser = myrialparser.Parser()\n",
    "processor = interpreter.StatementProcessor(fed_catalog, True)\n",
    "statement_list = parser.parse(program_fquery)\n",
    "processor.evaluate(statement_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Lets Visualize the query\n",
    "logical_plan = processor.get_logical_plan()\n",
    "dot_logical = raco.viz.operator_to_dot_object(logical_plan)\n",
    "dot_logical.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Lets optimize the query and let the federation figure out the right backends\n",
    "algebras = [OptLogicalAlgebra(), MyriaLeftDeepTreeAlgebra(), SparkAlgebra()]\n",
    "falg = FederatedAlgebra(algebras, fed_catalog)\n",
    "federated_plan = processor.get_physical_plan(target_alg=falg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Visualizing the physical plan\n",
    "raco.viz.operator_to_dot_object(federated_plan).view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Submit the plan for federated execution\n",
    "fed_conn.execute_query(federated_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
