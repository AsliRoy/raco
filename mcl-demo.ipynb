{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of the Myria Middleware \n",
    "\n",
    "The following code shows how [MCL Clustering](http://micans.org/mcl/) can be performed using the Myria Middleware and a [SPARK](http://spark.apache.org/) backend. \n",
    "\n",
    "\n",
    "### Setup steps:\n",
    "* Install Raco:\n",
    "    * Follow the steps listed on https://github.com/uwescience/raco/tree/SPJA_federation#setup to set up RACO.\n",
    "* Install SPARK:\n",
    "    * Download the prebuilt HADOOP version from http://spark.apache.org/downloads.html and follow the setup steps on SPARK website to verify if it works. (Make sure you have all the dependencies listed on the page installed)\n",
    "    * Set the SPARK_HOME environment variable to the downloaded SPARK folder and add it to PATH\n",
    "        * On mac, this can be done by adding the following lines to bash_profile or bashrc file:\n",
    "`\n",
    "export SPARK_HOME=</path/to/spark>\n",
    "export PATH=$SPARK_HOME/bin:$PATH\n",
    "`\n",
    "\n",
    "* Install jupyter:\n",
    "    * on mac, this can be done via: `pip install jupyter`\n",
    "    \n",
    "* Run `ipython notebook` command. And browse to this notebook. \n",
    "\n",
    "* Update the path to the input dataset in the code below^: \n",
    "`\n",
    "matA = scan('/path/to/datafile');\n",
    "`\n",
    "\n",
    "^ (As a sample, you can download and use https://github.com/uwescience/raco/blob/SPJA_federation/demo/sample.dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from raco.backends.spark.connection import SparkConnection\n",
    "from raco.backends.spark.catalog import SparkCatalog\n",
    "from raco.backends.spark.algebra import SparkAlgebra\n",
    "from raco.backends.myria.connection import MyriaConnection\n",
    "from raco.backends.myria.catalog import MyriaCatalog\n",
    "from raco.backends.myria import MyriaLeftDeepTreeAlgebra\n",
    "from raco.backends.federated.connection import FederatedConnection\n",
    "from raco.backends.federated.catalog import FederatedCatalog\n",
    "from raco.backends.federated import FederatedAlgebra\n",
    "from raco.backends.federated.algebra import FederatedExec\n",
    "from raco.compile import optimize\n",
    "\n",
    "import raco.myrial.interpreter as interpreter\n",
    "import raco.myrial.parser as myrialparser\n",
    "from optparse import OptionParser\n",
    "\n",
    "import raco.viz\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_myria_connection():\n",
    "    rest_url = 'https://rest.myria.cs.washington.edu:1776'\n",
    "    execution_url = 'http://demo.myria.cs.washington.edu'\n",
    "    connection = MyriaConnection(rest_url=rest_url,\n",
    "                                 execution_url=execution_url)\n",
    "    return connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spark_connection():\n",
    "    connection = SparkConnection('local')\n",
    "    return connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program_mcl = \"\"\"\n",
    "matA = scan('/users/shrainik/downloads/sample_small.dat');\n",
    "\n",
    "-- define constant values as singleton tables.\n",
    "epsilon = [0.001];\n",
    "prunelimit = [0.00001];\n",
    "\n",
    "-- initialize oldChaos and newChaos for stop condition.\n",
    "oldchaos = [1000];\n",
    "newchaos = [1000];\n",
    "\n",
    "-- while there is an epsilon improvement\n",
    "do\n",
    "    oldchaos = newchaos;\n",
    "\n",
    "    -- square matA\n",
    "    A = [from matA emit col as col_a, row as row_a, value as val_a];\n",
    "    B = [from matA emit col as col_b, row as row_b, value as val_b];\n",
    "    AxA = [from A, B\n",
    "           where col_a == row_b\n",
    "           emit row_a as row, col_b as col, sum(val_a * val_b) as value];\n",
    "\n",
    "    -- inflate operation\n",
    "    -- value will be value^2\n",
    "    squareA = [from AxA emit row, col, value * value as value];\n",
    "\n",
    "    colsums = [from squareA\n",
    "               emit squareA.col as col_c, sum(squareA.value) as colsum];\n",
    "\n",
    "    -- normalize newMatA\n",
    "    newMatA = [from squareA, colsums\n",
    "               where squareA.col == colsums.col_c\n",
    "               emit squareA.row as row, squareA.col as col, squareA.value/colsums.colsum as value];\n",
    "\n",
    "    -- pruning\n",
    "    prunedA = [from newMatA\n",
    "               where value > *prunelimit\n",
    "               emit *];\n",
    "\n",
    "    -- calculate newchaos\n",
    "    colssqs = [from prunedA\n",
    "               emit prunedA.col as col_sqs, sum (prunedA.value * prunedA.value) as sumSquare];\n",
    "    colmaxs = [from prunedA\n",
    "               emit prunedA.col as col_max, max (prunedA.value) as maxVal];\n",
    "\n",
    "    newchaos = [from colmaxs, colssqs\n",
    "                where colmaxs.col_max == colssqs.col_sqs\n",
    "                emit max (colmaxs.maxVal - colssqs.sumSquare)];\n",
    "\n",
    "    -- prepare for the iteration.\n",
    "    matA = prunedA;\n",
    "\n",
    "    -- check the convergency.\n",
    "    continue = [from newchaos, oldchaos emit (*oldchaos - *newchaos) > *epsilon];\n",
    "while continue;\n",
    "\n",
    "store (newchaos, '/users/shrainik/downloads/output.dat');\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myriaconn = get_myria_connection()\n",
    "sparkconn = get_spark_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myriacatalog = MyriaCatalog(myriaconn)\n",
    "sparkcatalog = SparkCatalog(sparkconn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myrial_code = program_mcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog = FederatedCatalog([myriacatalog, sparkcatalog])\n",
    "parser = myrialparser.Parser()\n",
    "processor = interpreter.StatementProcessor(catalog, True)\n",
    "statement_list = parser.parse(myrial_code)\n",
    "processor.evaluate(statement_list)\n",
    "\n",
    "algebras = [MyriaLeftDeepTreeAlgebra(), SparkAlgebra()]\n",
    "falg = FederatedAlgebra(algebras, catalog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logical = processor.get_logical_plan()\n",
    "federated_plan = processor.get_physical_plan(target_alg=falg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_logical = raco.viz.operator_to_dot_object(logical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dot_logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_federated = raco.viz.operator_to_dot_object(federated_plan)\n",
    "dot_federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "physical_plan_spark = optimize(federated_plan, SparkAlgebra())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phys_dot = raco.viz.operator_to_dot_object(physical_plan_spark)\n",
    "phys_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sparkconn.execute_query(physical_plan_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
